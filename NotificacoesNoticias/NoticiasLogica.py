import requests
from bs4 import BeautifulSoup

from Globais.Globais import nome_usuario


#Scraping
def scraping_ultimas_noticias():
    # Requisicao GET
    response = requests.get("https://www.dust2.com.br/")
    # Verificar requisicao
    if response.status_code != 200:
        raise Exception(f"Falha ao acessar o site. Status code: {response.status_code}")

    # Parsing do conteudo HTML
    soup = BeautifulSoup(response.content, 'html.parser')

    # Buscando titulo da noticia
    titulo_noticia = soup.find('div', class_='news-item-header')
    if not titulo_noticia:
        raise Exception("TÃ­tulo da notÃ­cia nÃ£o encontrado.")

    # Pegando o link da noticia
    link_noticia = soup.find('a', class_='a-block standard-box news-item big-article')
    if not link_noticia:
        raise Exception("Link da notÃ­cia nÃ£o encontrado.")

    link = link_noticia["href"]

    return titulo_noticia.text.strip(), f"https://www.dust2.com.br{link}"


def formatar_noticia():
    try:
        titulo_noticia, link = scraping_ultimas_noticias()
        resposta = (
            "ğŸ“° *Ãšltima notÃ­cia sobre o mundo EA SPORTS:*\n\n"
            f"*{titulo_noticia}*\n\n"
            f"ğŸ‘‰ Leia mais: {link}\n\n"
            "ğŸ”” Ative o recebimento automÃ¡tico de notÃ­cias com /receber_noticias ğŸ””"
        )
    except Exception as e:
        texto = f"âŒ NÃ£o foi possÃ­vel buscar a Ãºltima notÃ­cia:\n{e}"
    return resposta


def ultimas_noticias(bot,message):
    nome = nome_usuario.get(message.from_user.id, 'Furioso(a)')
    bot.reply_to(message, f'Eai {nome}! ğŸ”¥ Estamos bucando as Ãºltimas notÃ­cias para voce ficar 100% atualziado! ğŸ“…')
    bot.reply_to(message, formatar_noticia(), parse_mode='html')
